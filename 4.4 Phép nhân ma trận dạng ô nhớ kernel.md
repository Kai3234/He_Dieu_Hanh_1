# Mục tiêu
-Hiểu cách nhân [[ma trận dạng dạng ô nhớ]] kernel : 
	Tải và sử dụng ô nhớ để nhân ma trận
	Đồng bộ hóa [[rào cản]] và [[bộ nhớ chung]]
	Cân nhắc về tài nguyên
	Đơn giản hóa bằng việc giả sử chiều rộng là bội số của [[kích thước ô nhớ]]
# nhân ma trận dạng ô nhớ theo giai đoạn cụ thể (Phase)
## phase 0
![[Pasted image 20250222181733.png]]
Để truy cập ô nhớ 0 sử dụng 2D indexing:
	$M[Row][tx]$
	$N[ty][Col]$
## phase 1
![[Pasted image 20250222182011.png]]
Để truy cập ô nhớ 1 sử dụng 2D indexing;
	$M[Row][1*Tile-Width + tx]$
	$N[1*Tile-Width+ty][Col]$
## phân bổ động M và N sử dụng 1D [[indexing]]
Để truy cập ô nhớ thứ p:
	$M[Row][p*Tile-Width+tx]$
	$=> M[Row*Width + p*Tile_width +tx]$
	
	$N[p*Tile_Width+ty][Col]$
	$=>N[(p*Tile-Width+ty)*Width + Col]$ 
# Thuật toán nhân ma trận dạng ô nhớ
![[Pasted image 20250222183845.png]]

# Cân nhắc về kích thước ô nhớ ([[khối luồng]])
- Mỗi khối luồng cần có nhiều [[luồng (thread)]]:
	- Tile_width = 16 cho 16 * 16 = 256 luồng
	- Tile_width = 32 cho 32 * 32 = 1024 luồng
- Đối với 16, trong mỗi giai đoạn, mỗi khối thực hiện 2 * 256 = 512 tải nổi từ [[bộ nhớ toàn cục]] cho 256 * (2 * 16) = 8.192 hoạt động nhân hoặc cộng. (16 phép toán dấu phẩy động cho mỗi lần tải bộ nhớ).
# [[Bộ nhớ chia sẻ]] và luồng (thread)
- Đối với SM có bộ nhớ chia sẻ 16KB
	- Kích thước bộ nhớ chia sẻ phụ thuộc vào việc thực hiện.
	- Đối với TILE_WIDTH = 16, mỗi khối luồng sử dụng 2 * 256 * 4B = 2KB bộ nhớ dùng chung.
	- Đối với bộ nhớ chia sẻ 16KB, người ta có thể có tối đa 8 khối luồng thực thi:
		- Điều này cho phép lên đến 8 * 512 = 4,096 tải đang chờ xử lý. (2 mỗi luồng, 256 luồng mỗi khối)
	- TILE_WIDTH 32 tiếp theo sẽ dẫn đến việc sử dụng bộ nhớ được chia sẻ $2 * 32 * 32 * 4 Byte = 8K$ Byte trên mỗi khối luồng, cho phép 2 khối luồng hoạt động cùng một lúc.
		- Tuy nhiên, trong GPU mà số lượng luồng được giới hạn ở 1536 luồng trên mỗi SM, số khối trên mỗi SM giảm xuống còn một.
- Mỗi __syncthread() có thể giảm số lượng luồng hoạt động cho một khối:
	-> nhiều khối luồng sẽ có lợi hơn.