# 1. Mục tiêu:
Hiểu cách nhân ma trận dạng dạng [[ô|ô nhớ]] [[Kernel]] : 
- Tải và sử dụng [[ô|ô nhớ]] để nhân ma trận.
- [[Đồng bộ rào cản]] và [[bộ nhớ chia sẻ]].
- Cân nhắc về tài nguyên.
- Đơn giản hóa bằng việc giả sử chiều rộng là bội số của kích thước [[ô|ô nhớ]].

# 2. Thuật toán nhân ma trận dạng [[ô|ô nhớ]]:
### **Ý tưởng chính**:

Nhân ma trận dạng ô nhớ nhằm:

- Chia ma trận lớn thành các ma trận nhỏ hơn (các [[ô]]) vừa với **[[bộ nhớ chia sẻ]] (shared memory)** của [[GPU]].
    
- Tăng cường khả năng **tái sử dụng dữ liệu** bằng cách lưu trữ tạm thời các phần dữ liệu cần thiết trong [[bộ nhớ chia sẻ]], tránh phải truy cập [[bộ nhớ toàn cục]] (global memory) nhiều lần.
#### **Giả sử**: 
- Có hai ma trận đầu vào là **M**, **N** và ma trận kết quả là **P**. Để tận dụng tính song song và hiệu quả của [[bộ nhớ chia sẻ]], ta chia các ma trận thành các [[ô|ô nhớ]] với kích thước cố định, thường là `TILE_WIDTH x TILE_WIDTH`. Mỗi block của [[CUDA]] sẽ đảm nhận việc xử lý một [[ô|ô nhớ ]]của kết quả.

### **Các bước thực hiện thuật toán**:
> Khai báo shared memory để lưu ô nhớ của M và N:

![[Pasted image 20250324154919.png]]

> Xác định chỉ số hàng và cột của luồng trong ma trận P:

![[Pasted image 20250324155024.png]]

// trong đó: 
- `blockIdx.y` **và** `blockIdx.x`: Chỉ số của [[khối]] trong grid theo chiều dọc (y) và ngang (x). Mỗi [[khối]] trong grid đại diện cho một “[[ô|ô nhớ]]” của ma trận.
- `blockDim.y` **và** `blockDim.x`: Kích thước của [[khối]] theo chiều dọc và ngang (số lượng [[luồng]] trong [[khối]] theo từng chiều).
- `threadIdx.y` **và** `threadIdx.x`: Chỉ số của [[luồng]] bên trong [[khối]] theo hàng và cột. xác định vị trí của [[luồng]] trong [[ô|ô nhớ]].

//giải thích:
- Khi nhân `blockIdx` với `blockDim`, chúng ta "dịch chuyển" đến phần tử đầu tiên của [[khối]] ([[ô|ô nhớ]]) trong ma trận. Sau đó, cộng thêm `threadIdx` để xác định vị trí chính xác bên trong [[ô|ô nhớ]].

>  khởi tạo giá trị kết quả của phần tử P\[Row]\[Col]

![[Pasted image 20250324155140.png]]
	
>Vòng lặp qua tất cả các ô nhớ cần thiết để tính P\[Row]\[Col]:


// giải thích công thức:
- `Row * Width`: 
	- Tính toán vị trí bắt đầu của toàn bộ hàng có chỉ số `Row` trong mảng tuyến tính lưu trữ ma trận M.
	- **Ví dụ:** Nếu `Width = 8` và `Row = 2`, thì `Row * Width = 2 * 8 = 16` nghĩa là hàng thứ 2 bắt đầu tại chỉ số thứ 16 của mảng.
- `p * TILE_WIDTH + threadId.x`**:**
	- Xác định vị trí cột cho [[ô|ô nhớ]] hiện tại.
- kết hợp lại :
	- **Lấy phần tử ở hàng** `Row` **và cột** `(p * TILE_WIDTH + tx)` của ma trận M.
- tương tự với công N.

> Tính toán kết quả từng phần:

	    for (int i = 0; i < TILE_WIDTH; ++i)
	    {
		    Pvalue += ds_M[threadId.y][i] * ds_N[i][threadId.x];	
	    }
	
	    __synchthreads(); //đồng bộ trước khi load ô nhớ mới
	  } 
> Ghi kết quả vào ma trận P: 

	  P[Row*Width+Col] = Pvalue;
	}

## Phân tích thuật toán: 

- ==**Ưu điểm:**==
    
    - **Tăng hiệu quả truy cập bộ nhớ:** [[bộ nhớ chia sẻ||Shared memory ]]nhanh hơn [[bộ nhớ toàn cục||global memory]], do đó việc lưu trữ tạm các [[ô||ô nhớ]] trong [[bộ nhớ chia sẻ||shared memory]] giúp giảm số lần truy cập [[bộ nhớ toàn cục||global memory]].
        
    - **Tối ưu hóa song song:** Mỗi [[khối luồng|thread block]] có thể tính toán độc lập một [[ô|ô nhớ]], tận dụng tối đa khả năng [[tính toán song song]] của [[GPU]].
        
    - **Giảm băng thông [[bộ nhớ]]:** [[dữ liệu]] được tái sử dụng trong [[bộ nhớ chia sẻ|shared memory]] thay vì truy cập lại từ [[bộ nhớ toàn cục|global memory]].
        
- ==**Hạn chế:**==
    
    - **Giới hạn kích thước [[bộ nhớ chia sẻ|shared memory]]:** Kích thước TILE_WIDTH phải được chọn sao cho không vượt quá dung lượng [[bộ nhớ chia sẻ|shared memory]] của [[GPU]].
        
    - Các lệnh `__syncthreads()` cần thiết để đảm bảo tính chính xác, nhưng chúng cũng làm tăng chi phí tính toán.

# 3. Cân nhắc về kích thước [[ô|ô nhớ]] ([[khối luồng]])
- Mỗi [[khối luồng]] cần có nhiều [[luồng]]:
	- Tile_width = 16 cho 16 \* 16 = 256 [[luồng]].
	- Tile_width = 32 cho 32 \* 32 = 1024 [[luồng]].
- Đối với 16, trong mỗi [[pha|giai đoạn]], mỗi khối thực hiện 2 \* 256 = 512 tải nổi từ [[bộ nhớ toàn cục]] cho 256 \* (2 \* 16) = 8.192 hoạt động nhân hoặc cộng. (16 phép toán dấu phẩy động cho mỗi lần tải [[bộ nhớ]]).

# 4. [[Bộ nhớ chia sẻ]] và [[luồng]]
 Đối với SM có [[bộ nhớ chia sẻ]] 16KB
-  Kích thước [[bộ nhớ chia sẻ]] phụ thuộc vào việc thực hiện.
- Đối với TILE_WIDTH = 16, mỗi [[khối luồng]] sử dụng 2 \* 256 \* 4B = 2KB [[bộ nhớ chia sẻ]].
- Đối với [[bộ nhớ chia sẻ]] 16KB, người ta có thể có tối đa 8 [[khối luồng]] thực thi:
	- Điều này cho phép lên đến 8 * 512 = 4,096 tải đang chờ xử lý. (2 mỗi [[luồng]], 256 [[luồng]] mỗi [[khối]])
- TILE_WIDTH 32 tiếp theo sẽ dẫn đến việc sử dụng [[bộ nhớ chia sẻ|bộ nhớ được chia sẻ]]: 2 \* 32 \* 32 \* 4 Byte = 8 KByte trên mỗi [[khối luồng]], cho phép 2 [[khối luồng]] hoạt động cùng một lúc.
	- Tuy nhiên, trong [[GPU]] mà số lượng luồng được giới hạn ở 1536 [[luồng]] trên mỗi SM, số khối trên mỗi SM giảm xuống còn một.
- Mỗi __syncthread() có thể giảm số lượng [[luồng]] hoạt động cho một khối:
	-> nhiều [[khối luồng]] sẽ có lợi hơn.