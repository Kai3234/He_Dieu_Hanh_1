# 1. Mục tiêu
Hiểu cách nhân ma trận dạng dạng [[ô|ô nhớ]] kernel : 
- Tải và sử dụng [[ô|ô nhớ]] để nhân ma trận
- [[Đồng bộ rào cản]] và [[bộ nhớ chia sẻ]]
- Cân nhắc về tài nguyên
 - Đơn giản hóa bằng việc giả sử chiều rộng là bội số của kích thước [[ô|ô nhớ]].
# 2. Ví dụ về nhân ma trận dạng ô nhớ theo giai đoạn cụ thể [[pha|(phase)]]
## [[pha|Phase]] 0
![[Pasted image 20250222181733.png]]
- Để truy cập [[ô|ô nhớ]] 0 sử dụng 2D indexing:
![[Pasted image 20250313001027.png]]

## [[pha|Phase]] 1
![[Screenshot 2025-02-22 182009.png]]
- Để truy cập [[ô|ô nhớ]] 1 sử dụng 2D indexing;
![[Pasted image 20250313000938.png]]

## Phân bổ động M và N sử dụng 1D indexing
- Để truy cập [[ô|ô nhớ]] thứ p:
![[Pasted image 20250313000626.png]]

# 3. Thuật toán nhân ma trận dạng [[ô|ô nhớ]]:
![[Pasted image 20250313000343.png]]
![[Pasted image 20250313000428.png]]
![[Pasted image 20250313000500.png]]

## Phân tích thuật toán: 

- **Ưu điểm:**
    
    - **Tăng hiệu quả truy cập bộ nhớ:** [[bộ nhớ chia sẻ||Shared memory ]]nhanh hơn [[bộ nhớ toàn cục||global memory]], do đó việc lưu trữ tạm các [[ô||ô nhớ]] trong [[bộ nhớ chia sẻ||shared memory]] giúp giảm số lần truy cập global memory.
        
    - **Tối ưu hóa song song:** Mỗi thread block có thể tính toán độc lập một ô nhớ, tận dụng tối đa khả năng song song của GPU.
        
    - **Giảm băng thông bộ nhớ:** Dữ liệu được tái sử dụng trong shared memory thay vì truy cập lại từ global memory.
        
- **Hạn chế:**
    
    - **Giới hạn kích thước shared memory:** Kích thước TILE_WIDTH phải được chọn sao cho không vượt quá dung lượng shared memory của GPU.
        
    - **Overhead từ đồng bộ hóa:** Các lệnh `__syncthreads()` cần thiết để đảm bảo tính chính xác, nhưng chúng cũng làm tăng chi phí tính toán.


# 4. Cân nhắc về kích thước [[ô|ô nhớ]] ([[khối luồng]])
- Mỗi [[khối luồng]] cần có nhiều [[luồng]]:
	- Tile_width = 16 cho 16 * 16 = 256 [[luồng]].
	- Tile_width = 32 cho 32 * 32 = 1024 [[luồng]].
- Đối với 16, trong mỗi giai đoạn, mỗi khối thực hiện 2 * 256 = 512 tải nổi từ [[bộ nhớ toàn cục]] cho 256 * (2 * 16) = 8.192 hoạt động nhân hoặc cộng. (16 phép toán dấu phẩy động cho mỗi lần tải [[bộ nhớ]]).

# 5. [[Bộ nhớ chia sẻ]] và [[luồng]]
 Đối với SM có [[bộ nhớ chia sẻ]] 16KB
	- Kích thước [[bộ nhớ chia sẻ]] phụ thuộc vào việc thực hiện.
	- Đối với TILE_WIDTH = 16, mỗi khối luồng sử dụng 2 * 256 * 4B = 2KB [[bộ nhớ chia sẻ]].
	- Đối với [[bộ nhớ chia sẻ]] 16KB, người ta có thể có tối đa 8 [[khối luồng]] thực thi:
		- Điều này cho phép lên đến 8 * 512 = 4,096 tải đang chờ xử lý. (2 mỗi luồng, 256 luồng mỗi khối)
	- TILE_WIDTH 32 tiếp theo sẽ dẫn đến việc sử dụng [[bộ nhớ chia sẻ|bộ nhớ được chia sẻ]] $2 * 32 * 32 * 4 Byte = 8 KByte$  trên mỗi khối luồng, cho phép 2 [[khối luồng]] hoạt động cùng một lúc.
		- Tuy nhiên, trong [[GPU]] mà số lượng luồng được giới hạn ở 1536 [[luồng]] trên mỗi SM, số khối trên mỗi SM giảm xuống còn một.
- Mỗi __syncthread() có thể giảm số lượng [[luồng]] hoạt động cho một khối:
	-> nhiều [[khối luồng]] sẽ có lợi hơn.