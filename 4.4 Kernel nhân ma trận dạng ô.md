# 1. Mục tiêu:
Hiểu cách nhân [[ma trận]] dạng dạng [[ô|ô nhớ]] [[Kernel]] : 
- Tải và sử dụng [[ô|ô nhớ]] để nhân [[ma trận]].
- [[Đồng bộ rào cản]] và [[bộ nhớ chia sẻ]].
- Cân nhắc về tài nguyên.
- Đơn giản hóa bằng việc giả sử chiều rộng là bội số của kích thước [[ô|ô nhớ]].

# 2. Thuật toán nhân ma trận dạng [[ô|ô nhớ]]:

![[Code.png]]
### **Ý tưởng chính**:
#### Nhân [[ma trận]] dạng [[ô|ô nhớ]] nhằm:
- Chia [[ma trận]] lớn thành các [[ma trận]] nhỏ hơn (các [[ô]]) vừa với **[[bộ nhớ chia sẻ]] (shared memory)** của [[GPU]].
    
- Tăng cường khả năng **tái sử dụng [[dữ liệu]]** bằng cách lưu trữ tạm thời các phần [[dữ liệu]] cần thiết trong [[bộ nhớ chia sẻ]], tránh phải truy cập [[bộ nhớ toàn cục]] (global memory) nhiều lần.
### **Giả sử**: 
- Có hai [[ma trận]] đầu vào là **M**, **N** và [[ma trận]] kết quả là **P**. Để tận dụng tính song song và hiệu quả của [[bộ nhớ chia sẻ]], ta chia các [[ma trận]] thành các [[ô|ô nhớ]] với kích thước cố định, thường là `TILE_WIDTH x TILE_WIDTH`. Mỗi block của [[CUDA]] sẽ đảm nhận việc xử lý một [[ô|ô nhớ]] của kết quả.

### **Các bước thực hiện thuật toán**:
> **Khai báo shared memory để lưu ô nhớ của M và N:**

![[Khai_báo.png]]

> **Xác định chỉ số hàng và cột của [[luồng]] trong [[ma trận]] P:**

![[chỉ_số.png]]

// **trong đó:** 

- `blockIdx.y` **và** `blockIdx.x`: Chỉ số của [[khối]] trong grid theo chiều dọc (x) và ngang (y). Mỗi [[khối]] trong grid đại diện cho một “[[ô|ô nhớ]]” của [[ma trận]].

- `blockDim.y` **và** `blockDim.x`: Kích thước của [[khối]] theo chiều dọc và ngang (số lượng [[luồng]] trong [[khối]] theo từng chiều).

- `threadIdx.y` **và** `threadIdx.x`: Chỉ số của [[luồng]] bên trong [[khối]] theo hàng và cột, xác định vị trí của [[luồng]] trong [[ô|ô nhớ]].

// **giải thích:**
- Khi nhân `blockIdx` với `blockDim`, chúng ta "dịch chuyển" đến phần tử đầu tiên của [[khối]] ([[ô|ô nhớ]]) trong ma trận. 
- Sau đó cộng thêm `threadIdx` để xác định vị trí chính xác bên trong [[ô|ô nhớ]].


>  **khởi tạo giá trị kết quả của phần tử P\[Row]\[Col]:**

![[giá_trị_ô.png]]
	
>**Vòng lặp qua tất cả các ô nhớ cần thiết để tính P\[Row]\[Col]:**

![[Tải_ô_nhớ.png]]

// **giải thích công thức:**
- `Row * Width`: 
	- Tính toán vị trí bắt đầu của toàn bộ hàng có chỉ số `Row` trong mảng tuyến tính lưu trữ ma trận M.
	- **Ví dụ:** Nếu `Width = 8` và `Row = 2`, thì `Row * Width = 2 * 8 = 16` nghĩa là hàng thứ 2 bắt đầu tại chỉ số thứ 16 của mảng.
- `p * TILE_WIDTH + threadId.x`**:**
	- Xác định vị trí cột cho [[ô|ô nhớ]] hiện tại.
- kết hợp lại :
	- **Lấy phần tử ở hàng** `Row` **và cột** `(p * TILE_WIDTH + tx)` của ma trận M.
- tương tự với công thức ma trận N.

> **Tính toán kết quả từng phần:**

![[tính_toán.png]]

> **Ghi kết quả vào ma trận P:** 

![[gán_giá_trị.png]]
### Phân tích [[thuật toán]]: 

- **Ưu điểm:**
    - **Tăng hiệu quả [[truy cập bộ nhớ]]:** [[bộ nhớ chia sẻ|Shared memory]] nhanh hơn [[bộ nhớ toàn cục|global memory]], do đó việc lưu trữ tạm các [[ô|ô nhớ]] trong [[bộ nhớ chia sẻ|shared memory]] giúp giảm số lần truy cập [[bộ nhớ toàn cục|global memory]].

    - **[[Tối ưu hóa]] song song:** Mỗi [[khối luồng|thread block]] có thể tính toán độc lập một [[ô|ô nhớ]], tận dụng tối đa khả năng [[tính toán song song]] của [[GPU]].
        
    - **Giảm [[băng thông]] [[bộ nhớ]]:** [[dữ liệu]] được tái sử dụng trong [[bộ nhớ chia sẻ|shared memory]] thay vì truy cập lại từ [[bộ nhớ toàn cục|global memory]].
        
- **Hạn chế:**
    - **Giới hạn kích thước [[bộ nhớ chia sẻ|shared memory]]:** Kích thước TILE_WIDTH phải được chọn sao cho không vượt quá [[dung lượng]] [[bộ nhớ chia sẻ|shared memory]] của [[GPU]].
        
    - Các lệnh `__syncthreads()` cần thiết để đảm bảo tính chính xác, nhưng chúng cũng làm tăng chi phí tính toán.

# 3. Cân nhắc về kích thước [[ô|ô nhớ]] ([[khối luồng]])
- Mỗi [[khối luồng]] cần có nhiều [[luồng]]:

		 Tile_width = 16 cho 16 x 16 = 256 luồng.
		 Tile_width = 32 cho 32 x 32 = 1024 luồng.
- Đối với 16, trong mỗi [[pha|giai đoạn]], mỗi khối thực hiện:

			2 x 256 = 512 tải nổi từ bộ nhớ toàn cục.
		Tổng số phép toán tương ứng: 
			256 × (2 × 16) = 8.192 phép toán nhân hoặc cộng
		(Đây là số phép toán dấu phẩy động, với mỗi lần tải từ bộ nhớ bao gồm 16 phép toán dấu phẩy động).

-> Cần cân nhắc kích thước tối ưu của **Tile_width** dựa trên khả năng [[phần cứng]], [[băng thông]] [[bộ nhớ]] và [[mức độ song song]] của [[ứng dụng]].

-> Việc [[tối ưu hóa]] **[[khối luồng]]** không chỉ ảnh hưởng đến [[hiệu suất]] tổng thể mà còn giúp giảm thiểu [[xung đột truy cập]] [[bộ nhớ toàn cục]].

# 4. [[Bộ nhớ chia sẻ]] và [[luồng]]
- Đối với [[SM]] có [[bộ nhớ chia sẻ]] 16KB:
	- Kích thước [[bộ nhớ chia sẻ]] phụ thuộc vào cách triển khai:
	
			Với TILE_WIDTH = 16, mỗi khối luồng sử dụng:
				2 x 256 x 4 Byte = 2 KB
			Với bộ nhớ chia sẻ 16 KB, ta có thể thực thi tối đa 8 khối luồng.
			-> điều này cho phép tới:
				8 x 512 = 4096 tải đang chờ xử lý (2 mỗi luồng, và 256 luồng mỗi khối)
	- Đối với `TILE_WIDTH = 32`, sẽ dẫn đến:
	
			 - 2 x 32 x 32 x 4 Byte = 8 KB bộ nhớ chia sẻ được sử dụng trên mỗi khối luồng.
			 - cho phép 2 khối luồng hoạt động cùng lúc.
			 - Tuy nhiên, trong một GPU mà số lượng luồng được giới hạn ở 1.536 luồng trên mỗi SM -> số khối trên mỗi SM sẽ giảm xuống còn một.

- Mỗi lệnh `__syncthreads()` có thể làm giảm số lượng [[luồng]] hoạt động của một [[khối]].

		-> nhiều khối luồng hơn có thể có lợi hơn

		