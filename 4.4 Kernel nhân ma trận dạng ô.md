# 1. Mục tiêu: 
Hiểu cách nhân ma trận dạng dạng [[ô|ô nhớ]] kernel : 
- Tải và sử dụng [[ô|ô nhớ]] để nhân ma trận.
- [[Đồng bộ rào cản]] và [[bộ nhớ chia sẻ]].
- Cân nhắc về tài nguyên.
- Đơn giản hóa bằng việc giả sử chiều rộng là bội số của kích thước [[ô|ô nhớ]].

# 2. Thuật toán nhân ma trận dạng [[ô|ô nhớ]]:

> Khai báo shared memory để lưu ô nhớ của M và N:

	__global__ void MatrixMulKernel(float* M, float* N, float* P, Int Width)
	{
	  __shared__ float ds_M[TILE_WIDTH][TILE_WIDTH];
	
	  __shared__ float ds_N[TILE_WIDTH][TILE_WIDTH];

> Xác định chỉ số hàng và cột của luồng trong ma trận P:

	  int bx = blockIdx.x;  int by = blockIdx.y;
	
	  int tx = threadIdx.x; int ty = threadIdx.y;
	
	  int Row = by * blockDim.y + ty;
	
	  int Col = bx * blockDim.x + tx;

>  Giá trị kết quả của phần tử P\[Row]\[Col]

	  float Pvalue = 0;
	
>Vòng lặp qua tất cả các ô nhớ cần thiết để tính P\[Row]\[Col]:

	 for (int p = 0; p < n/TILE_WIDTH; ++p) {
	
	    // Tải một ô nhớ từ M và N vào shared memory
	
	    ds_M[ty][tx] = M[Row*Width + p*TILE_WIDTH+tx];
	
	    ds_N[ty][tx] = N[(t*TILE_WIDTH+ty)*Width + Col];
	
	    __syncthreads(); // đồng bộ giữa các luồng
> Tính toán kết quả từng phần:

	    for (int i = 0; i < TILE_WIDTH; ++i)Pvalue += ds_M[ty][i] * ds_N[i][tx];
	
	    __synchthreads(); //đồng bộ trước khi load ô nhớ mới
	  } 
> Ghi kết quả vào ma trận P: 

	  P[Row*Width+Col] = Pvalue;
	}

## Phân tích thuật toán: 

- ==**Ưu điểm:**==
    
    - **Tăng hiệu quả truy cập bộ nhớ:** [[bộ nhớ chia sẻ||Shared memory ]]nhanh hơn [[bộ nhớ toàn cục||global memory]], do đó việc lưu trữ tạm các [[ô||ô nhớ]] trong [[bộ nhớ chia sẻ||shared memory]] giúp giảm số lần truy cập [[bộ nhớ toàn cục||global memory]].
        
    - **Tối ưu hóa song song:** Mỗi [[khối luồng|thread block]] có thể tính toán độc lập một [[ô|ô nhớ]], tận dụng tối đa khả năng [[tính toán song song]] của [[GPU]].
        
    - **Giảm băng thông [[bộ nhớ]]:** [[dữ liệu]] được tái sử dụng trong [[bộ nhớ chia sẻ|shared memory]] thay vì truy cập lại từ [[bộ nhớ toàn cục|global memory]].
        
- ==**Hạn chế:**==
    
    - **Giới hạn kích thước [[bộ nhớ chia sẻ|shared memory]]:** Kích thước TILE_WIDTH phải được chọn sao cho không vượt quá dung lượng [[bộ nhớ chia sẻ|shared memory]] của [[GPU]].
        
    - Các lệnh `__syncthreads()` cần thiết để đảm bảo tính chính xác, nhưng chúng cũng làm tăng chi phí tính toán.

# 3. Ví dụ về nhân ma trận dạng ô nhớ theo giai đoạn cụ thể [[pha|(phase)]]:

#### **Giả sử**: có hai ma trận đầu vào là **M**, **N** và ma trận kết quả là **P**. Để tận dụng tính song song và hiệu quả của [[bộ nhớ chia sẻ]], ta chia các ma trận thành các [[ô|ô nhớ]] với kích thước cố định, thường là `TILE_WIDTH x TILE_WIDTH`. Mỗi block của [[CUDA]] sẽ đảm nhận việc xử lý một [[ô|ô nhớ ]]của kết quả.
## [[pha|Phase]] 0
![[Pasted image 20250222181733.png]]
- Để truy cập [[ô|ô nhớ]] 0 sử dụng 2D indexing:
![[Pasted image 20250313001027.png]]

## [[pha|Phase]] 1
![[Screenshot 2025-02-22 182009.png]]
- Để truy cập [[ô|ô nhớ]] 1 sử dụng 2D indexing;
![[Pasted image 20250313000938.png]]

## Phân bổ động M và N sử dụng 1D indexing:
- Để truy cập [[ô|ô nhớ]] thứ p:
![[Pasted image 20250313000626.png]]


# 4. Cân nhắc về kích thước [[ô|ô nhớ]] ([[khối luồng]])
- Mỗi [[khối luồng]] cần có nhiều [[luồng]]:
	- Tile_width = 16 cho 16 * 16 = 256 [[luồng]].
	- Tile_width = 32 cho 32 * 32 = 1024 [[luồng]].
- Đối với 16, trong mỗi [[pha|giai đoạn]], mỗi khối thực hiện 2 * 256 = 512 tải nổi từ [[bộ nhớ toàn cục]] cho 256 * (2 * 16) = 8.192 hoạt động nhân hoặc cộng. (16 phép toán dấu phẩy động cho mỗi lần tải [[bộ nhớ]]).

# 5. [[Bộ nhớ chia sẻ]] và [[luồng]]
 Đối với SM có [[bộ nhớ chia sẻ]] 16KB
	- Kích thước [[bộ nhớ chia sẻ]] phụ thuộc vào việc thực hiện.
	- Đối với TILE_WIDTH = 16, mỗi [[khối luồng]] sử dụng 2 * 256 * 4B = 2KB [[bộ nhớ chia sẻ]].
	- Đối với [[bộ nhớ chia sẻ]] 16KB, người ta có thể có tối đa 8 [[khối luồng]] thực thi:
		- Điều này cho phép lên đến 8 * 512 = 4,096 tải đang chờ xử lý. (2 mỗi [[luồng]], 256 [[luồng]] mỗi [[khối]])
	- TILE_WIDTH 32 tiếp theo sẽ dẫn đến việc sử dụng [[bộ nhớ chia sẻ|bộ nhớ được chia sẻ]] $2 * 32 * 32 * 4 Byte = 8 KByte$  trên mỗi [[khối luồng]], cho phép 2 [[khối luồng]] hoạt động cùng một lúc.
		- Tuy nhiên, trong [[GPU]] mà số lượng luồng được giới hạn ở 1536 [[luồng]] trên mỗi SM, số khối trên mỗi SM giảm xuống còn một.
- Mỗi __syncthread() có thể giảm số lượng [[luồng]] hoạt động cho một khối:
	-> nhiều [[khối luồng]] sẽ có lợi hơn.